{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VBMP-Yd_I_ep",
        "outputId": "5798331a-47c9-432f-aaeb-e2109baf7db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eliminar 100% NaN: ['Resultados Ultima auditoria Inventario']\n",
            "Obras únicas: 187 | Filas: 381\n",
            "Numéricas (excl. Bodega): ['Resultados Ultima Ev OT', 'Resultados Ultima AO', 'Avance Fisico', 'Cantidad Inv Generales Previos', 'Stock', 'Cantidad de Auditorias', 'Resultados Ultima Evaluacion Obra']\n",
            "Roles (TE): ['Gerente de Proyecto', 'Administrador de Obra', 'Oficina Tecnica', 'Jefes de Bodega']\n",
            "Categóricas OHE: ['Empresa']\n",
            "Resultados Ultima Bodega (MinMaxScaler): ['Resultados Ultima Bodega']\n",
            "\n",
            "CV (GroupKFold) -> R²: -0.027 | MAE: 0.128 | RMSE: 0.167\n",
            "\n",
            "Importancia de las Características:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                              Feature  Importance\n",
              "9                                     Oficina Tecnica    0.497421\n",
              "10                                    Jefes de Bodega    0.186154\n",
              "8                               Administrador de Obra    0.086428\n",
              "4                                               Stock    0.038124\n",
              "7                                 Gerente de Proyecto    0.036723\n",
              "2                                       Avance Fisico    0.032839\n",
              "6                   Resultados Ultima Evaluacion Obra    0.024402\n",
              "3                      Cantidad Inv Generales Previos    0.022609\n",
              "23                           Resultados Ultima Bodega    0.020449\n",
              "1                                Resultados Ultima AO    0.018346\n",
              "0                             Resultados Ultima Ev OT    0.010566\n",
              "12                    Empresa_CONSTRUCTORA NOVAL LTDA    0.009734\n",
              "5                              Cantidad de Auditorias    0.004644\n",
              "20                               Empresa_GEOVITA S.A.    0.004242\n",
              "21                                  Empresa_ICEM S.A.    0.002061\n",
              "16        Empresa_EMPRESA CONSTRUCTORA FE GRANDE S.A.    0.001936\n",
              "15                    Empresa_CONSTRUCTORA SALFA S.A.    0.001030\n",
              "18  Empresa_EMPRESA DE MANTENCIONES Y SERVICIOS SA...    0.000993\n",
              "17            Empresa_EMPRESA CONSTRUCTORA TECSA S.A.    0.000379\n",
              "14                  Empresa_CONSTRUCTORA NOVATEC S.A.    0.000356\n",
              "13        Empresa_CONSTRUCTORA NOVATEC EDIFICIOS S.A.    0.000278\n",
              "19  Empresa_EMPRESA DE MONTAJES INDUSTRIALES SALFA...    0.000252\n",
              "11               Empresa_CONST. BRISAS DE BATUCO S.A.    0.000033\n",
              "22                         Empresa_infrequent_sklearn    0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b367b314-1e30-4fc0-8256-cdb7f3c40a35\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Oficina Tecnica</td>\n",
              "      <td>0.497421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Jefes de Bodega</td>\n",
              "      <td>0.186154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Administrador de Obra</td>\n",
              "      <td>0.086428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Stock</td>\n",
              "      <td>0.038124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Gerente de Proyecto</td>\n",
              "      <td>0.036723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Avance Fisico</td>\n",
              "      <td>0.032839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Resultados Ultima Evaluacion Obra</td>\n",
              "      <td>0.024402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cantidad Inv Generales Previos</td>\n",
              "      <td>0.022609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Resultados Ultima Bodega</td>\n",
              "      <td>0.020449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Resultados Ultima AO</td>\n",
              "      <td>0.018346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Resultados Ultima Ev OT</td>\n",
              "      <td>0.010566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Empresa_CONSTRUCTORA NOVAL LTDA</td>\n",
              "      <td>0.009734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Cantidad de Auditorias</td>\n",
              "      <td>0.004644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Empresa_GEOVITA S.A.</td>\n",
              "      <td>0.004242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Empresa_ICEM S.A.</td>\n",
              "      <td>0.002061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Empresa_EMPRESA CONSTRUCTORA FE GRANDE S.A.</td>\n",
              "      <td>0.001936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Empresa_CONSTRUCTORA SALFA S.A.</td>\n",
              "      <td>0.001030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Empresa_EMPRESA DE MANTENCIONES Y SERVICIOS SA...</td>\n",
              "      <td>0.000993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Empresa_EMPRESA CONSTRUCTORA TECSA S.A.</td>\n",
              "      <td>0.000379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Empresa_CONSTRUCTORA NOVATEC S.A.</td>\n",
              "      <td>0.000356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Empresa_CONSTRUCTORA NOVATEC EDIFICIOS S.A.</td>\n",
              "      <td>0.000278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Empresa_EMPRESA DE MONTAJES INDUSTRIALES SALFA...</td>\n",
              "      <td>0.000252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Empresa_CONST. BRISAS DE BATUCO S.A.</td>\n",
              "      <td>0.000033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Empresa_infrequent_sklearn</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b367b314-1e30-4fc0-8256-cdb7f3c40a35')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b367b314-1e30-4fc0-8256-cdb7f3c40a35 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b367b314-1e30-4fc0-8256-cdb7f3c40a35');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-eca93ab0-92be-4f73-9d9b-3dddbe003f37\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eca93ab0-92be-4f73-9d9b-3dddbe003f37')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-eca93ab0-92be-4f73-9d9b-3dddbe003f37 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    main()\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"Feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"Resultados Ultima Bodega\",\n          \"Empresa_CONSTRUCTORA SALFA S.A.\",\n          \"Oficina Tecnica\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Importance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10506374492547026,\n        \"min\": 0.0,\n        \"max\": 0.4974214830133741,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          0.02044915895326609,\n          0.001029676001852366,\n          0.4974214830133741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Umbral (max F1): 0.77 | P: 0.54 | R: 0.95 | F1: 0.69\n",
            "Umbral mínimo con recall≥0.70: 0.71\n",
            "\n",
            "=== Clasificación de alarma (<70%) con umbral=0.710 (OOF por obra) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          OK       0.61      0.42      0.49       195\n",
            "     AUDITAR       0.54      0.72      0.62       186\n",
            "\n",
            "    accuracy                           0.56       381\n",
            "   macro avg       0.57      0.57      0.56       381\n",
            "weighted avg       0.58      0.56      0.55       381\n",
            "\n",
            "\n",
            "Predicciones y Importancia de Variables guardadas exitosamente en 'plantilla_con_predicciones.xlsx'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Importar módulos necesarios para la construcción y evaluación del modelo\n",
        "from sklearn.model_selection import GroupKFold, cross_val_score, cross_val_predict\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor, GradientBoostingRegressor # HistGradientBoostingRegressor está comentado\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n",
        "# Transformador personalizado para la codificación de destino suavizada (Smoothed Target Encoding)\n",
        "class SmoothedTargetEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, cols=None, smoothing=10.0):\n",
        "        self.cols = cols\n",
        "        self.smoothing = float(smoothing)\n",
        "        self.maps_ = {} # Diccionario para almacenar mapeos\n",
        "        self.global_mean_ = None # Media global de la variable objetivo\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Ajustar el codificador a los datos de entrenamiento\n",
        "        X = pd.DataFrame(X, copy=True)\n",
        "        y = pd.Series(y)\n",
        "        self.global_mean_ = y.mean() # Calcular la media global\n",
        "        tmp = X.copy()\n",
        "        tmp[\"_y\"] = y.values\n",
        "        self.maps_.clear()\n",
        "        if self.cols:\n",
        "            for c in self.cols:\n",
        "                if c not in tmp.columns:\n",
        "                    continue\n",
        "                # Calcular la media del destino suavizada para cada categoría\n",
        "                g = tmp.groupby(c)[\"_y\"].agg([\"mean\",\"count\"]).rename(columns={\"mean\":\"mu\",\"count\":\"N\"})\n",
        "                enc = (g[\"N\"]*g[\"mu\"] + self.smoothing*self.global_mean_) / (g[\"N\"] + self.smoothing)\n",
        "                self.maps_[c] = enc.to_dict() # Almacenar mapeo\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Transformar los datos usando los mapeos aprendidos\n",
        "        X = pd.DataFrame(X, copy=True)\n",
        "        for c, mp in self.maps_.items():\n",
        "            if c in X.columns:\n",
        "                # Aplicar mapeo y llenar valores faltantes con la media global\n",
        "                X[c] = X[c].map(mp).fillna(self.global_mean_)\n",
        "        return X\n",
        "\n",
        "    def get_feature_names_out(self, input_features=None):\n",
        "        # Obtener nombres de las características de salida\n",
        "        return np.array(input_features if input_features is not None else (self.cols or []))\n",
        "\n",
        "\n",
        "# Función de ayuda para encontrar la primera columna entre una lista de opciones\n",
        "def first_col(df, options):\n",
        "    for c in options:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "# Función de ayuda para convertir una serie a una proporción entre 0 y 1\n",
        "def to_ratio_0_1(s):\n",
        "    x = pd.to_numeric(s, errors=\"coerce\").astype(float)\n",
        "    if np.nanmean(x > 1) > 0.1:\n",
        "        x = x / 100.0\n",
        "    return x.clip(0, 1) # Recortar valores para que estén entre [0, 1]\n",
        "\n",
        "# Función de ayuda para asignar un estado de \"semáforo\" basado en un valor\n",
        "def semaforo(v):\n",
        "    if v >= 0.85: return \"Verde\"\n",
        "    if v >= 0.60: return \"Amarillo\"\n",
        "    return \"Rojo\"\n",
        "\n",
        "\n",
        "# Función para cargar y preprocesar los datos para entrenamiento\n",
        "def load_and_preprocess_data(file_path):\n",
        "    df = pd.read_excel(file_path, sheet_name=\"Dataset de Testeo\")\n",
        "\n",
        "    # Identificar la columna para el ID de la obra\n",
        "    OBRA_ID_COL = first_col(df, [\"Obra\",\"PEP\"])\n",
        "    if OBRA_ID_COL is None:\n",
        "        # Crear OBRA_ID si no se encuentra\n",
        "        df[\"OBRA_ID\"] = df[first_col(df, df.columns)].astype(str).str.extract(r\"(SCCOM\\d+|[A-Z]{2,}\\d+)\", expand=False)\n",
        "        OBRA_ID_COL = \"OBRA_ID\"\n",
        "\n",
        "    # Identificar y procesar la columna de fecha de inicio de auditoría\n",
        "    fecha_ini_col = first_col(df, [\"Fecha Inicio Auditoría\",\"Fecha Inicio Auditoria\",\"Fecha Auditoría\",\"Fecha Auditoria\"])\n",
        "    if fecha_ini_col is not None:\n",
        "        df[fecha_ini_col] = pd.to_datetime(df[fecha_ini_col], dayfirst=True, errors=\"coerce\")\n",
        "        # Ordenar por ID de obra y fecha\n",
        "        df = df.sort_values([OBRA_ID_COL, fecha_ini_col])\n",
        "    else:\n",
        "        df = df.sort_values([OBRA_ID_COL]).reset_index(drop=True)\n",
        "\n",
        "    # Renombrar columnas para consistencia\n",
        "    rename_map = {\n",
        "        \"Administrador\": \"Administrador de Obra\",\n",
        "        \"Oficina Técnica\": \"Oficina Tecnica\",\n",
        "        \"Jefe de bodega\": \"Jefes de Bodega\",\n",
        "        \"Avance Físico\": \"Avance Fisico\",\n",
        "    }\n",
        "    for k,v in rename_map.items():\n",
        "        if k in df.columns and v not in df.columns:\n",
        "            df[v] = df[k]\n",
        "\n",
        "    # Convertir columnas de evaluación y stock a numéricas\n",
        "    for c in [\"Evaluación Obra\",\"Evaluación Bodega\",\"Evaluación OT\",\"Evaluación AO\",\"Stock\",\"Avance Fisico\"]:\n",
        "        if c in df.columns:\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "    # Identificar y procesar la columna de porcentaje de inventario\n",
        "    inv_pct_col = first_col(df, [\n",
        "        \"Valor porcentual sobre stock\", \"% Diferencia sobre Stock\",\n",
        "        \"Porcentaje sobre Stock\", \"InvPctSobreStock\", \"Diferencia Absoluta %\"\n",
        "    ])\n",
        "    if inv_pct_col is None:\n",
        "        df[\"InvPctSobreStock_EXCEL\"] = np.nan\n",
        "        inv_pct_col = \"InvPctSobreStock_EXCEL\"\n",
        "    df[inv_pct_col] = to_ratio_0_1(df[inv_pct_col])\n",
        "\n",
        "    # === AÑADIDO: Resultado de la última evaluación de Obra ===\n",
        "    # Añadir columnas para los resultados de la última evaluación para diferentes áreas\n",
        "    df[\"Resultados Ultima Evaluacion Obra\"] = df.groupby(OBRA_ID_COL)[\"Evaluación Obra\"].shift(1)\n",
        "\n",
        "    df[\"Resultados Ultima Bodega\"] = df.groupby(OBRA_ID_COL)[\"Evaluación Bodega\"].shift(1) if \"Evaluación Bodega\" in df.columns else np.nan\n",
        "    ot_src = first_col(df, [\"Evaluación OT\",\"Evaluación OTDiferencia Absoluta\"])\n",
        "    df[\"Resultados Ultima Ev OT\"] = df.groupby(OBRA_ID_COL)[ot_src].shift(1) if ot_src else np.nan\n",
        "    df[\"Resultados Ultima AO\"] = df.groupby(OBRA_ID_COL)[\"Evaluación AO\"].shift(1) if \"Evaluación AO\" in df.columns else np.nan\n",
        "    df[\"Resultados Ultima auditoria Inventario\"] = df.groupby(OBRA_ID_COL)[inv_pct_col].shift(1)\n",
        "\n",
        "    # Añadir una columna para el número de auditorías previas\n",
        "    if \"Cantidad de Auditorias\" not in df.columns:\n",
        "        df[\"Cantidad de Auditorias\"] = df.groupby(OBRA_ID_COL).cumcount()\n",
        "\n",
        "    # Imputar valores faltantes inicialmente por Empresa\n",
        "    for c in [\"Resultados Ultima Bodega\", \"Resultados Ultima Ev OT\", \"Resultados Ultima AO\",\n",
        "              \"Resultados Ultima auditoria Inventario\", \"Avance Fisico\", \"Stock\",\n",
        "              \"Resultados Ultima Evaluacion Obra\"]: # <- Añadido\n",
        "        if c in df.columns and \"Empresa\" in df.columns:\n",
        "            df[c] = df.groupby(\"Empresa\")[c].transform(lambda s: s.fillna(s.mean()))\n",
        "            df[c] = df[c].fillna(df[c].mean()) # Llenar los NaNs restantes con la media global\n",
        "\n",
        "    return df, OBRA_ID_COL\n",
        "\n",
        "\n",
        "# Función para hacer predicciones en nuevos datos\n",
        "def predecir(df_nuevo: pd.DataFrame, pipe, cols_present, thr_recall70, best_f1_row, usar_umbral_recall70: bool=True) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Puntúa nuevas filas con el regresor; aplica semáforo y alarma.\n",
        "    Scores new rows with the regressor; applies semaphore and alarm.\n",
        "    \"\"\"\n",
        "    d = df_nuevo.copy()\n",
        "\n",
        "    # Renombrar columnas en los nuevos datos para consistencia\n",
        "    rmap = {\n",
        "        \"Administrador\": \"Administrador de Obra\",\n",
        "        \"Oficina Técnica\": \"Oficina Tecnica\",\n",
        "        \"Jefe de bodega\": \"Jefes de Bodega\",\n",
        "        \"Avance Físico\": \"Avance Fisico\",\n",
        "    }\n",
        "    for k,v in rmap.items():\n",
        "        if k in d.columns and v not in d.columns:\n",
        "            d[v] = d[k]\n",
        "\n",
        "    # Añadir columnas faltantes con valores NaN\n",
        "    for c in cols_present:\n",
        "        if c not in d.columns:\n",
        "            d[c] = np.nan\n",
        "\n",
        "    # Llenar valores faltantes en columnas categóricas y de roles con 'missing_val'\n",
        "    cat_ohe_cols = [\"Empresa\", \"Auditor\"]\n",
        "    roles_te_cols = [\"Gerente de Proyecto\", \"Administrador de Obra\", \"Oficina Tecnica\", \"Jefes de Bodega\"]\n",
        "    for c in cat_ohe_cols + roles_te_cols:\n",
        "        if c in d.columns:\n",
        "            d[c] = d[c].fillna('missing_val').astype(str)\n",
        "\n",
        "    # Hacer predicciones usando el pipeline entrenado\n",
        "    y_hat = pipe.predict(d[cols_present])\n",
        "\n",
        "    # Determinar el umbral a usar para la clasificación\n",
        "    thr = float(thr_recall70) if usar_umbral_recall70 else float(best_f1_row.threshold)\n",
        "\n",
        "    # Crear el DataFrame de salida con predicciones, estado del semáforo y alarma\n",
        "    out = pd.DataFrame({\n",
        "        \"pred_eval_obra\": y_hat,\n",
        "        \"semaforo\": [semaforo(v) for v in y_hat],\n",
        "        \"alarma_<70%\": (y_hat < thr).astype(int),\n",
        "        \"umbral_usado\": thr\n",
        "    })\n",
        "    return out\n",
        "\n",
        "# Función principal para ejecutar el proceso de entrenamiento y predicción del modelo\n",
        "def main():\n",
        "    # Cargar y preprocesar los datos de entrenamiento\n",
        "    df, OBRA_ID_COL = load_and_preprocess_data(\"Prueba prediccion Auditorias.xlsx\")\n",
        "\n",
        "    # Convertir la variable objetivo a numérica y filtrar valores inválidos\n",
        "    df[\"Evaluación Obra\"] = pd.to_numeric(df[\"Evaluación Obra\"], errors=\"coerce\")\n",
        "    df = df[df[\"Evaluación Obra\"].between(1e-3, 1-1e-3)].copy()\n",
        "\n",
        "    # === Modificado: Se agrega \"Resultados Ultima Evaluacion Obra\" a USE_COLS ===\n",
        "    # Definir las columnas a usar para el entrenamiento\n",
        "    USE_COLS = [\n",
        "        \"Resultados Ultima Bodega\",\n",
        "        \"Resultados Ultima Ev OT\",\n",
        "        \"Resultados Ultima AO\",\n",
        "        \"Resultados Ultima auditoria Inventario\",\n",
        "        \"Gerente de Proyecto\",\n",
        "        \"Administrador de Obra\",\n",
        "        \"Oficina Tecnica\",\n",
        "        \"Jefes de Bodega\",\n",
        "        \"Empresa\",\n",
        "        \"Avance Fisico\",\n",
        "        \"Cantidad Inv Generales Previos\",\n",
        "        \"Stock\",\n",
        "        \"Cantidad de Auditorias\",\n",
        "        \"Resultados Ultima Evaluacion Obra\", # Añadido\n",
        "    ]\n",
        "\n",
        "    # Verificar columnas faltantes y añadirlas con valores NaN\n",
        "    missing = [c for c in USE_COLS if c not in df.columns]\n",
        "    if missing:\n",
        "        print(\"¡Ojo! Faltaban columnas y se crearán vacías (se imputan):\", missing)\n",
        "        for c in missing:\n",
        "            df[c] = np.nan\n",
        "\n",
        "    # Definir columnas categóricas y de roles\n",
        "    cat_ohe_cols = [\"Empresa\", \"Auditor\"]\n",
        "    roles_te_cols = [\"Gerente de Proyecto\", \"Administrador de Obra\", \"Oficina Tecnica\", \"Jefes de Bodega\"]\n",
        "\n",
        "    # Llenar valores faltantes en columnas categóricas y de roles\n",
        "    for c in cat_ohe_cols + roles_te_cols:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].fillna('missing_val').astype(str)\n",
        "\n",
        "    # Obtener la lista de columnas presentes en el DataFrame\n",
        "    cols_present = USE_COLS[:]\n",
        "    y = df[\"Evaluación Obra\"].values # Variable objetivo\n",
        "    groups = df[OBRA_ID_COL].astype(str).values # Variable de agrupación para validación cruzada\n",
        "\n",
        "    # Eliminar columnas con todos los valores NaN\n",
        "    all_nan = [c for c in cols_present if df[c].isna().all()]\n",
        "    if all_nan:\n",
        "        print(\"Eliminar 100% NaN:\", all_nan)\n",
        "        cols_present = [c for c in cols_present if c not in all_nan]\n",
        "\n",
        "    # Separar columnas por tipo para el preprocesamiento\n",
        "    roles_te = [c for c in roles_te_cols if c in cols_present]\n",
        "    cat_ohe  = [c for c in cat_ohe_cols if c in cols_present]\n",
        "    num_cols = [c for c in cols_present if c not in roles_te + cat_ohe]\n",
        "\n",
        "    # Eliminar 'Resultados Ultima Bodega' de num_cols para aplicar escalado separado\n",
        "    bodega_col = \"Resultados Ultima Bodega\"\n",
        "    if bodega_col in num_cols:\n",
        "        num_cols.remove(bodega_col)\n",
        "        bodega_col_present = True\n",
        "    else:\n",
        "        bodega_col_present = False\n",
        "\n",
        "\n",
        "    print(f\"Obras únicas: {pd.Series(groups).nunique()} | Filas: {len(df)}\")\n",
        "    print(\"Numéricas (excl. Bodega):\", num_cols)\n",
        "    print(\"Roles (TE):\", roles_te)\n",
        "    print(\"Categóricas OHE:\", cat_ohe)\n",
        "    if bodega_col_present:\n",
        "        print(\"Resultados Ultima Bodega (MinMaxScaler):\", [bodega_col])\n",
        "\n",
        "\n",
        "    # Definir los pasos de preprocesamiento usando ColumnTransformer\n",
        "    transformers = []\n",
        "    if num_cols:\n",
        "        transformers.append((\"num\", SimpleImputer(strategy=\"median\"), num_cols)) # Imputar columnas numéricas con la mediana\n",
        "    if roles_te:\n",
        "        transformers.append((\"roles_te\", SmoothedTargetEncoder(cols=roles_te, smoothing=10), roles_te)) # Aplicar Smoothed Target Encoding a columnas de roles\n",
        "    if cat_ohe:\n",
        "        transformers.append((\"ohe\", OneHotEncoder(handle_unknown=\"infrequent_if_exist\",\n",
        "                                                  min_frequency=5, sparse_output=False), cat_ohe)) # Aplicar One-Hot Encoding a columnas categóricas\n",
        "    if bodega_col_present:\n",
        "         transformers.append((\"bodega_scaler\", Pipeline([('imputer', SimpleImputer(strategy=\"median\")), ('scaler', MinMaxScaler())]), [bodega_col])) # Añadir MinMaxScaler para Bodega\n",
        "\n",
        "\n",
        "    # Verificar si hay transformadores definidos\n",
        "    if not transformers:\n",
        "        raise ValueError(\"No hay columnas para entrenar el modelo.\")\n",
        "\n",
        "    # Crear el ColumnTransformer\n",
        "    pre = ColumnTransformer(\n",
        "        transformers=transformers,\n",
        "        remainder=\"drop\", # Eliminar columnas no especificadas en los transformadores\n",
        "        verbose_feature_names_out=False\n",
        "    )\n",
        "\n",
        "    # Definir el modelo (Gradient Boosting Regressor)\n",
        "    model = GradientBoostingRegressor( # Cambiado a GradientBoostingRegressor\n",
        "        learning_rate=0.03,\n",
        "        max_depth=5,\n",
        "        n_estimators=100, # Añadido n_estimators para GradientBoostingRegressor\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Crear el pipeline con preprocesamiento y modelo\n",
        "    pipe = Pipeline([\n",
        "        (\"pre\", pre),\n",
        "        (\"model\", model)\n",
        "    ])\n",
        "\n",
        "    # Configurar GroupKFold para validación cruzada\n",
        "    n_splits = max(2, min(5, pd.Series(groups).nunique()))\n",
        "    gkf = GroupKFold(n_splits=n_splits)\n",
        "\n",
        "    # Realizar validación cruzada e imprimir métricas\n",
        "    r2 = cross_val_score(pipe, df[cols_present], y, cv=gkf, groups=groups, scoring=\"r2\", n_jobs=-1).mean()\n",
        "    mae = -cross_val_score(pipe, df[cols_present], y, cv=gkf, groups=groups, scoring=\"neg_mean_absolute_error\", n_jobs=-1).mean()\n",
        "    rmse = np.sqrt(-cross_val_score(pipe, df[cols_present], y, cv=gkf, groups=groups, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean())\n",
        "    print(f\"\\nCV (GroupKFold) -> R²: {r2:.3f} | MAE: {mae:.3f} | RMSE: {rmse:.3f}\")\n",
        "\n",
        "    # Ajustar el pipeline a todos los datos de entrenamiento\n",
        "    pipe.fit(df[cols_present], y)\n",
        "    # Obtener predicciones fuera de pliegue para evaluación de clasificación\n",
        "    y_pred_reg = cross_val_predict(pipe, df[cols_present], y, cv=gkf, groups=groups, n_jobs=-1)\n",
        "\n",
        "    # Imprimir importancia de las características\n",
        "    feature_importances = None\n",
        "    try:\n",
        "        # Verificar si el modelo tiene feature_importances_ o un atributo similar\n",
        "        if hasattr(pipe.named_steps['model'], 'feature_importances_'):\n",
        "            feature_importances = pipe.named_steps['model'].feature_importances_\n",
        "            # Obtener nombres de las características después del preprocesamiento\n",
        "            feature_names = pipe.named_steps['pre'].get_feature_names_out()\n",
        "            # Crear un DataFrame para la importancia de las características\n",
        "            importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
        "            importance_df = importance_df.sort_values('Importance', ascending=False)\n",
        "            print(\"\\nImportancia de las Características:\")\n",
        "            display(importance_df)\n",
        "        else:\n",
        "            print(\"\\nNo se pudo obtener la importancia de las características: El modelo no tiene un atributo 'feature_importances_'.\")\n",
        "            print(\"Considere usar un modelo como RandomForestRegressor o GradientBoostingRegressor si la importancia de las características es crucial.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nOcurrió un error inesperado al intentar obtener la importancia de las características: {e}\")\n",
        "\n",
        "\n",
        "    # Evaluar el rendimiento de clasificación para diferentes umbrales\n",
        "    y_true_alarm = (y < 0.70).astype(int) # Definir las etiquetas de alarma verdaderas\n",
        "    grid = np.linspace(0.40, 0.80, 41) # Definir una cuadrícula de umbrales a evaluar\n",
        "\n",
        "    rows = []\n",
        "    for t in grid:\n",
        "        y_hat = (y_pred_reg < t).astype(int) # Predecir alarma basada en el umbral\n",
        "        # Calcular métricas de clasificación\n",
        "        TP = ((y_true_alarm==1) & (y_hat==1)).sum()\n",
        "        FP = ((y_true_alarm==0) & (y_hat==1)).sum()\n",
        "        FN = ((y_true_alarm==1) & (y_hat==0)).sum()\n",
        "        precision = TP / (TP+FP) if (TP+FP)>0 else 0.0\n",
        "        recall    = TP / (TP+FN) if (TP+FN)>0 else 0.0\n",
        "        f1        = 2*precision*recall/(precision+recall) if (precision+recall)>0 else 0.0\n",
        "        rows.append((t, precision, recall, f1))\n",
        "\n",
        "    # Crear un DataFrame con los resultados de la evaluación de umbrales\n",
        "    thr_df = pd.DataFrame(rows, columns=[\"threshold\",\"precision\",\"recall\",\"f1\"])\n",
        "    # Encontrar el umbral que maximiza el puntaje F1\n",
        "    best_f1_row = thr_df.iloc[thr_df[\"f1\"].idxmax()]\n",
        "    print(\"\\nUmbral (max F1):\", round(best_f1_row.threshold,3),\n",
        "          \"| P:\", round(best_f1_row.precision,2),\n",
        "          \"| R:\", round(best_f1_row.recall,2),\n",
        "          \"| F1:\", round(best_f1_row.f1,2))\n",
        "\n",
        "    # Encontrar el umbral mínimo que alcanza un recall de al menos 0.70\n",
        "    cand = thr_df[thr_df[\"recall\"] >= 0.70]\n",
        "    if not cand.empty:\n",
        "        thr_recall70 = float(cand.threshold.min())\n",
        "        print(\"Umbral mínimo con recall≥0.70:\", round(thr_recall70,3))\n",
        "    else:\n",
        "        thr_recall70 = float(best_f1_row.threshold)\n",
        "        print(\"No se alcanzó recall≥0.70; uso umbral de F1:\", round(thr_recall70,3))\n",
        "\n",
        "    # Establecer el umbral final para la clasificación de alarma\n",
        "    THRESHOLD = float(thr_recall70)\n",
        "    y_hat_final = (y_pred_reg < THRESHOLD).astype(int) # Predicciones finales de alarma\n",
        "    print(f\"\\n=== Clasificación de alarma (<70%) con umbral={THRESHOLD:.3f} (OOF por obra) ===\")\n",
        "    # Imprimir el informe de clasificación\n",
        "    print(classification_report(y_true_alarm, y_hat_final, target_names=[\"OK\",\"AUDITAR\"]))\n",
        "\n",
        "    # Cargar el archivo de plantilla para nuevas predicciones\n",
        "    try:\n",
        "        df_plantilla = pd.read_excel(\"plantilla_pre_auditoria.xlsx\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"\\nError: No se encontró el archivo 'plantilla_pre_auditoria.xlsx'.\")\n",
        "        return\n",
        "\n",
        "    # Llenar valores faltantes en columnas categóricas y de roles en los datos de la plantilla\n",
        "    cat_ohe_cols = [\"Empresa\", \"Auditor\"]\n",
        "    roles_te_cols = [\"Gerente de Proyecto\", \"Administrador de Obra\", \"Oficina Tecnica\", \"Jefes de Bodega\"]\n",
        "    for c in cat_ohe_cols + roles_te_cols:\n",
        "        if c in df_plantilla.columns:\n",
        "            df_plantilla[c] = df_plantilla[c].fillna('missing_val').astype(str)\n",
        "\n",
        "    # Hacer predicciones en los datos de la plantilla\n",
        "    resultados_prediccion = predecir(df_plantilla, pipe, cols_present, thr_recall70, best_f1_row, usar_umbral_recall70=True)\n",
        "\n",
        "    # Concatenar los datos de la plantilla con los resultados de la predicción\n",
        "    df_plantilla_con_prediccion = pd.concat([df_plantilla, resultados_prediccion], axis=1)\n",
        "\n",
        "    # Guardar las predicciones y la importancia de las características en un archivo de Excel\n",
        "    try:\n",
        "        with pd.ExcelWriter(\"plantilla_con_predicciones.xlsx\") as writer:\n",
        "            df_plantilla_con_prediccion.to_excel(writer, sheet_name='Predicciones', index=False)\n",
        "            if feature_importances is not None:\n",
        "                 importance_df.to_excel(writer, sheet_name='Importancia de Variables', index=False)\n",
        "\n",
        "        print(\"\\nPredicciones y Importancia de Variables guardadas exitosamente en 'plantilla_con_predicciones.xlsx'.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError al guardar el archivo: {e}\")\n",
        "\n",
        "# Ejecutar la función principal cuando se ejecuta el script\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}